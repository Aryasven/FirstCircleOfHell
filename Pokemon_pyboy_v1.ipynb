{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1rktZ1RL-D5lc6CDrdpZ5vitUq2MZjssb","timestamp":1719727773923}],"private_outputs":true,"gpuType":"T4","mount_file_id":"1rktZ1RL-D5lc6CDrdpZ5vitUq2MZjssb","authorship_tag":"ABX9TyM6O4oI9dPM4rhxVlDbrJio"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"09nhHG-wYzE8"},"outputs":[],"source":["!pip install -q -U google-generativeai\n","!pip install pyboy\n","\n","!sudo apt install tesseract-ocr\n","!pip install pytesseract"]},{"cell_type":"code","source":["!pip install transformers datasets\n","\n","from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n","from PIL import Image\n","import requests\n","import torch"],"metadata":{"id":"T45v2fWPZuzI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load a pre-trained TrOCR model and processor\n","processor = TrOCRProcessor.from_pretrained('microsoft/trocr-small-printed')\n","model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-small-printed')"],"metadata":{"id":"IBC_OqIDhPF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load an example image\n","image = Image.open('/content/drive/MyDrive/Colab Notebooks/Pokebot/image.png').convert('RGB')\n","\n","# Preprocess the image\n","pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n","\n","# Predict text from the image\n","model.eval()  # Set model to evaluation mode\n","with torch.no_grad():\n","    generated_ids = model.generate(pixel_values)\n","\n","# Decode the predicted text\n","predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n","\n","# Step 8: Display the predicted text\n","print(\"Predicted text:\", predicted_text)"],"metadata":{"id":"3ZtDmbIdnnI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load OCR model\n","import keras_ocr\n","\n","detector = keras_ocr.detection.Detector(weights='clovaai_general')\n","detector.model.load_weights('/content/drive/MyDrive/Colab Notebooks/Pokebot/KerasOCRmodel/detector_weights.h5')\n","recognizer = keras_ocr.recognition.Recognizer(alphabet=recognizer_alphabet,weights='kurapan')\n","\n","pipeline = keras_ocr.pipeline.Pipeline(detector=detector, recognizer=recognizer)\n","\n","predictions = pipeline.recognize(images=[image])[0]"],"metadata":{"id":"CCm714y47woN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pathlib\n","import textwrap\n","\n","import google.generativeai as genai\n","\n","from IPython.display import display\n","from IPython.display import Markdown\n","\n","\n","def to_markdown(text):\n","  text = text.replace('â€¢', '  *')\n","  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"],"metadata":{"id":"9oUYxOZVZbtf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Used to securely store your API key\n","from google.colab import userdata\n","# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n","GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n","\n","genai.configure(api_key=GOOGLE_API_KEY)"],"metadata":{"id":"hI_HXylIZdyJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from scipy import signal\n","\n","def check_frame_change(prev_frame, current_frame):\n","  # Convert images to numpy arrays for comparison\n","  current_frame_array = np.array(current_frame)\n","  prev_frame_array = np.array(prev_frame)\n","\n","  # cor = signal.correlate(prev_frame_array, current_frame_array)\n","\n","  # Check if the frames are different\n","  if np.array_equal(current_frame_array, prev_frame_array):\n","      return False\n","  else:\n","    # print(cor)\n","    return True\n","\n","def check_not_empty(current_frame):\n","  extrema = current_frame.getextrema()\n","  if extrema[0] == extrema[1]:\n","    # This image is one solid color, so dont process it\n","    empty = True\n","  else:\n","    empty = False\n","\n","  return not empty\n"],"metadata":{"id":"d6F6PeCKm_iM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyboy import PyBoy\n","import pytesseract\n","from IPython.display import display\n","import copy\n","\n","rom_path = './drive/MyDrive/Colab Notebooks/Pokebot/Pokemon_Red.gb'\n","# rom_path = 'Pokemon\\ROM\\Pokemon_Red.gb'\n","pyboy = PyBoy(rom_path)\n","\n","# Select the Gemini-Pro-Vision model\n","model = genai.GenerativeModel(\"gemini-pro-vision\")"],"metadata":{"id":"TCa3_TafmqAc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["intro_prompt = \"You are going to play a game where you are the main character.\\\n","For all future prompts,\\\n","your aim is to raise creatures called pokemon by battling them with other pokemon.\\\n","Each pokemon has some skills that can used to attack other pokemon.\\\n","You need to understand what is on the screen and suggest the correct action to take.\\\n","Some actions can be like asking you for a name, asking to pick between few options, and \\\n","also battling an opponent, by choosing a pokemon and some skills.\\\n","Your outputs will be used directly to play the game through a python code. \\\n","So keep your outputs short and display them in the form of comma separated instructions \\\n","on how to navigate the screen to continue playing the game.\\\n","Respond 'Yes' to this.\"\n","\n","# Text prompt (optional)\n","text_prompt1 = \"Read the text in the image. Decide if it is asking you to take an action or not.\\\n","If there is no text respond 0. \\\n","If the text is just telling a story, respond 1\\\n","If the text is asking for an action or choice, respond 2.\"\n","\n","text_prompt2 = \"Read the question in the image.\\\n","Pick an answer. Mention the chosen answer.\\\n","If the question asks for name. Pick an existing name. \\\n","Find the current cursor position. Right-pointing triangle shape is the cursor.\\\n","Given the current cursor position, give instructions to take the cursor to the chosen answer.\\\n","Then Give the instructions as a sequence of these commands :RIGHT, LEFT, UP, DOWN in the form of a list.\\\n","Do not respond in comeplete sentences.\\\n","Response should include only the chosen answer and the sequence of instructions.\""],"metadata":{"id":"C7QnOg6Nch1Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import output\n","pyboy = PyBoy(rom_path)\n","\n","action = 1\n","prev_frame = None\n","frame_count = 0\n","\n","story = []\n","\n","while pyboy.tick(120,False):\n","  frame_count+=1\n","\n","  # Start the game\n","  if frame_count == 1:\n","    pyboy.button('start', True)\n","    pil_image = pyboy.screen.image\n","    grayscale_image = pil_image.convert('L')\n","    combined_input = [intro_prompt, grayscale_image]\n","    response = model.generate_content(combined_input)\n","    print(response.text)\n","    prev_frame = pil_image\n","\n","  else:\n","    # Extract the current frame as an image\n","    pil_image = pyboy.screen.image\n","    frame_change_check = check_frame_change(prev_frame, pil_image)\n","    chk_image = check_not_empty(pil_image)\n","\n","    # if chk_image:\n","    if frame_change_check:\n","      print('Frames are different')\n","      # Perform OCR on the image\n","      extracted_text = pytesseract.image_to_string(pil_image)\n","      # print(\"Extracted text:\")\n","      print(extracted_text)\n","      story.append(extracted_text)\n","      if prev_frame_change_check:\n","        pyboy.button('a', True)\n","\n","    elif frame_change_check ==0 and chk_image:\n","      # Combine text and image for input (list format)\n","      rgb_image = pil_image.convert('RGB')\n","      combined_input = [text_prompt1, rgb_image]\n","\n","      # Generate response\n","      response1 = model.generate_content(combined_input)\n","      print('Model response ',response1.text)\n","      if response1.text == '1':\n","        # Print the response\n","        print(response1.text)\n","        pyboy.button('a', True)\n","        # display(pil_image)\n","        # break\n","      elif response1.text =='2':\n","        display(pil_image)\n","        combined_input = [text_prompt2, rgb_image]\n","        # Generate response\n","        response2 = model.generate_content(combined_input)\n","        print(response2.text)\n","\n","  output.clear()\n","  display(pil_image)\n","  prev_frame = pil_image\n","  prev_frame_change_check =frame_change_check\n","  if frame_count > 100:\n","    break"],"metadata":{"id":"mEsxMwLzUU0_"},"execution_count":null,"outputs":[]}]}